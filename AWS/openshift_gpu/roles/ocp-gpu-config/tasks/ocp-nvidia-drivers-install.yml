---

- name: "Enable rhel-7-server-optional-rpm repository"
  rhsm_repository:
    name: rhel-7-server-optional-rpms

- name: "Install require repos"
  yum:
    name: " {{ item }}"
    state: present
  with_items:
    - http://mirrors.oit.uci.edu/epel/epel-release-latest-7.noarch.rpm
    - https://developer.download.nvidia.com/compute/cuda/repos/rhel7/x86_64/cuda-repo-rhel7-10.0.130-1.x86_64.rpm

- name: "Download repository for libnviida-container and nvidia-container-runtime"
  get_url:
    url: https://nvidia.github.io/nvidia-container-runtime/centos7/nvidia-container-runtime.repo
    dest: /etc/yum.repos.d/nvidia-container-runtime.repo
    mode: 644

- name: "install required packages for nvidia driver setup"
  yum:
    name: " {{ item }}"
    state: present
  with_items:
    - kernel-devel-{{ ansible_kernel }}
    - nvidia-driver
    - nvidia-driver-cuda
    - nvidia-modprobe 
    - nvidia-container-runtime-hook

- name: "Remove the noveau kernel module"
  shell: 
    modprobe -r nouveau

- name: "Load the NVIDIA and unified memory kernel modules"
  shell:
    nvidia-modprobe && nvidia-modprobe -u
    
- name: "Extract the GPU name and register it to variable"
  shell:
    nvidia-smi --query-gpu=gpu_name --format=csv,noheader --id=0 | sed -e 's/ /-/g'
  register: gpu_name

- debug:
    var: gpu_name.stdout_lines

- name: "copy selinux policy module nvidia-container.pp over to gpu node(s)"
  copy:
    src: roles/ocp-gpu-config/files/nvidia-container.pp
    dest: /home/ec2-user/nvidia-container.pp

- name: "Install SELinux policy module on all GPU worker nodes"
  shell: semodule -i /home/ec2-user/nvidia-container.pp

- name: "Restorecon all files that the prestart hook needs"
  shell: nvidia-container-cli -k list | restorecon -v -f -

- name: "restorecon all accessed devices and files"
  shell: restorecon -Rv {{ item }}
  with_items:
    - /dev
    - /var/lib/kubelet
