AWSTemplateFormatVersion: 2010-09-09
Description: Baseline Splunk setup for new account
Parameters:
  KinesisAccountID:
     Default: na
     Description: AWS Account Number that manages kinesis streams
     Type: String
Mappings: 
  RegionMap: 
    us-east-1: 
      region: e1
      regionname: east1
    us-east-2: 
      region: e2
      regionname: east2
    us-west-1: 
      region: w1
      regionname: west1
    us-west-2: 
      region: w2
      regionname: west2
Resources:
  CWHealthEventRule:
    Type: 'AWS::Events::Rule'
    Properties:
      Name: CloudWatch_Health_Event 
      Description: This event will be triggered every time an AWS Health Event is triggered.
      EventPattern: 
        source: 
          - aws.health
        detail-type: 
          - "AWS Health Event"
      State: "ENABLED"
      Targets: 
        - Arn:
            'Fn::GetAtt':
              - SQSHealthEventsQueue
              - Arn
          Id: SQSHealthEventsTargetId
          
  SQSHealthEventsQueue:
    Type: AWS::SQS::Queue
    Properties: 
      DelaySeconds: 0
      MaximumMessageSize: 256000
      MessageRetentionPeriod: 345600
      QueueName: sqs-health-events-splunk
      ReceiveMessageWaitTimeSeconds: 0
      RedrivePolicy: 
        deadLetterTargetArn: 
          Fn::GetAtt: 
            - "SQSHealthEventsDLQueue"
            - "Arn"
        maxReceiveCount: 1 
      VisibilityTimeout: 300

  SQSHealthEventsDLQueue: 
    Type: AWS::SQS::Queue   
    Properties:
      DelaySeconds: 0
      MaximumMessageSize: 256000
      MessageRetentionPeriod: 345600
      QueueName: sqs-health-events-splunk-deadletter
      ReceiveMessageWaitTimeSeconds: 0
      VisibilityTimeout: 30     

  SQSS3AccessLogsQueue:
    Type: AWS::SQS::Queue
    Properties: 
      DelaySeconds: 0
      MaximumMessageSize: 256000
      MessageRetentionPeriod: 345600
      QueueName: sqs-s3-access-logs-splunk
      ReceiveMessageWaitTimeSeconds: 0
      RedrivePolicy: 
        deadLetterTargetArn: 
          Fn::GetAtt: 
            - "SQSS3AccessLogsDLQueue"
            - "Arn"
        maxReceiveCount: 1 
      VisibilityTimeout: 300

  SQSS3AccessLogsDLQueue: 
    Type: AWS::SQS::Queue
    Properties:
      DelaySeconds: 0
      MaximumMessageSize: 256000
      MessageRetentionPeriod: 345600
      QueueName: sqs-s3-access-logs-splunk-deadletter
      ReceiveMessageWaitTimeSeconds: 0
      VisibilityTimeout: 30

  SQSS3Policy:
    Type: 'AWS::SQS::QueuePolicy'
    Properties:
      PolicyDocument:
        Id: PushS3NotificationsToSQSPolicy
        Version: 2012-10-17
        Statement:
          - Sid: allow-s3-to-send-message-to-sqs
            Effect: Allow
            Action:
              - 'sqs:SendMessage'
            Principal:
              AWS: '*'
            Resource: '*'
            Condition:
              ArnEquals:
                'aws:SourceArn': "arn:aws:s3:::*"
      Queues:
        - !Ref SQSS3AccessLogsQueue

  S3AccessLoggingBucket:
    Type: AWS::S3::Bucket
    DependsOn: SQSS3Policy
    DeletionPolicy: Delete
    Properties:
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        IgnorePublicAcls: true
        BlockPublicPolicy: true
        RestrictPublicBuckets: true
      AccessControl: LogDeliveryWrite
      BucketName: 
        !Sub
          - '${AWS::AccountId}-s3-access-logs-${USRegion}'
          - { USRegion: !FindInMap [RegionMap, !Ref 'AWS::Region', region]}
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
      NotificationConfiguration:
        QueueConfigurations:
          - Event: 's3:ObjectCreated:*'
            Queue: !GetAtt SQSS3AccessLogsQueue.Arn

  S3EventRule:
    Type: 'AWS::Events::Rule'
    DependsOn: S3AccessLoggingBucket
    Properties:
      Name: New-S3Bucket-Event
      Description: 'Trigger a Lambda function anytime a new S3 bucket is created '
      EventPattern:
        source: 
          - aws.s3
        detail-type:
          - AWS API Call via CloudTrail
        detail:
          eventSource:
            - s3.amazonaws.com
          eventName:
            - CreateBucket
      State: ENABLED
      Targets:
        - 
          Arn: 
            Fn::GetAtt: 
              - "LFEnableBucketLogging"
              - "Arn"
          Id: "LFEnableBucketLoggingProduction"

  LFEnableBucketLogging:
    Type: 'AWS::Lambda::Function'
    Properties:
      Description: This function enables access logging on newly created S3 Buckets. 
      Handler: index.lambda_handler 
      Role: !GetAtt 
        - LFEnableBucketLoggingRole
        - Arn
      Runtime: python3.7
      Timeout: '60'
      Code:
        ZipFile: |
          import boto3
          import logging

          logger = logging.getLogger()
          logger.setLevel(logging.INFO)

          def enable_logging(bucketname,targetbucket):

              is_bucket_logging_enabled = False
              client = boto3.client('s3')
              try:
                  response = client.put_bucket_logging(
                      Bucket=bucketname,
                      BucketLoggingStatus={
                          'LoggingEnabled': {
                              'TargetBucket': targetbucket,
                              'TargetPrefix': bucketname
                          }
                      },
                  )
                  logger.info(response)
                  is_bucket_logging_enabled = True
              except Exception as e:
                  logger.error(e)
              finally:
                  return is_bucket_logging_enabled

          def lambda_handler(event, context):
              try:
                  region = event['region']
                  detail = event['detail']
                  eventname = detail['eventName']

                  regiondict = {'us-east-1':'e1', 'us-east-2':'e2', 'us-west-1':'w1', 'us-west-2':'w2'}
                  logger.info('region: ' + str(region))
                  logger.info('eventName: ' + str(eventname))
                  logger.info('detail: ' + str(detail))

                  if not detail['requestParameters']:
                      logger.warning('No requestParameters found')
                      if detail['errorCode']:
                          logger.error('errorCode: ' + detail['errorCode'])
                      if detail['errorMessage']:
                          logger.error('errorMessage: ' + detail['errorMessage'])
                      return False

                  if eventname == 'CreateBucket':
                      s3bucketname = detail['requestParameters']['bucketName']
                      logger.info(s3bucketname)
                  else:
                      logger.warning('Not supported action')

                  if s3bucketname:
                      #Extract account id where the bucket is being created
                      accountid = boto3.client('sts').get_caller_identity()['Account']

                      #bucket name of the s3 access logging bucket
                      targetbucket = "{0}-s3-access-logs-{1}".format(accountid,regiondict[region])

                      logger.info('accountid: ' + str(accountid))
                      logger.info('targetbucket: ' + str(targetbucket))

                      response = enable_logging(s3bucketname,targetbucket)
                      logger.info(response)

              except Exception as e:
                  logger.error('Error message: ' + str(e))
  LFEnableBucketLoggingLG:
    Type: 'AWS::Logs::LogGroup'
    DependsOn: LFEnableBucketLogging
    DeletionPolicy: Retain
    Properties:
      LogGroupName:
        'Fn::Join':
          - ''
          - - /aws/lambda/
            - Ref: LFEnableBucketLogging
      RetentionInDays: 14
  PermissionForS3EventsToInvokeLambda:
    Type: 'AWS::Lambda::Permission'
    Properties:
      FunctionName: 
        Ref: LFEnableBucketLogging
      Action: 'lambda:InvokeFunction'
      Principal: events.amazonaws.com
      SourceArn:
        Fn::GetAtt: 
          - S3EventRule
          - Arn
  LFEnableBucketLoggingRole:
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Policies:
        - PolicyName: LFEnableBucketLoggingPolicy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Sid: Stmt1458923121000
                Effect: Allow
                Action:
                  - 's3:PutBucketLogging'
                  - 'logs:CreateLogGroup'
                  - 'logs:CreateLogStream'
                  - 'logs:PutLogEvents'
                Resource:
                  - '*'

  CWLogEventRule:
    Type: 'AWS::Events::Rule'
    Properties:
      Description: >-
        Trigger a Lambda function anytime a new CWLog resource is created (Cloud Watch Log Group)
      EventPattern:
        source: 
          - aws.logs
        detail-type:
          - AWS API Call via CloudTrail
        detail:
          eventSource:
            - logs.amazonaws.com
          eventName:
            - CreateLogGroup
      Name: Account-Vending-CWLogGroup-Creation
      State: ENABLED
      Targets:
        - 
          Arn: 
            Fn::GetAtt: 
              - "LFCWApplySubFilter"
              - "Arn"
          Id: "LFCWApplySubFilterProd"

  LFCWApplySubFilter:
    Type: 'AWS::Lambda::Function'
    Properties:
      Environment:
        Variables:
          KinesisAccount: !Ref KinesisAccountID
      Description: This function applies subscription filter to specific log groups. 
      Handler: index.lambda_handler 
      Role: !GetAtt 
        - LFCWApplySubFilterRole
        - Arn
      Runtime: python3.7 
      Timeout: '60'
      Code:
        ZipFile: |
          import boto3
          import botocore
          import time
          import os
          import json
          import logging

          logger = logging.getLogger()
          logger.setLevel(logging.INFO)

          def create_subscription_filters(filtername,destinationArn,logGroupName,deployregion):
              subscription_filter_created = False
              session = boto3.session.Session()
              # Create CloudWatchLogs client
              cloudwatch_logs = session.client(
                  service_name='logs',
                  region_name=deployregion
              )
              try:
                  # Create a subscription filter
                  response = cloudwatch_logs.put_subscription_filter(
                      destinationArn=destinationArn,
                      filterName=filtername,
                      filterPattern='',
                      logGroupName=logGroupName,
                  )
                  logger.info(response)
                  subscription_filter_created = True
              except botocore.exceptions.ClientError as e:
                  logger.info("The request could not be completed:", e)
              finally:
                  return response

          def lambda_handler(event,context):

              is_subscription_filter_created = False
              KinesisAccount = os.environ['KinesisAccount']
              regiondict = {'us-east-1':'east1', 'us-east-2':'east2', 'us-west-1':'west1', 'us-west-2':'west2'}

              kinesisstreamprefix = 'splunk-kinesis-stream'
              loggrouparray = ['/aws/lambda/AA','/aws/aes/','RDSOSMetrics','/aws/rds/cluster','/aws/lambda/Soteria','/aws/lambda/CloudWatch_Health_Event','API-Gateway']
              filternamepostfixarray = ['cloudwatch-lambda','cloudwatch-elasticsearch','rdsosmetrics','rdslogs','soteria','cloudwatch-events','apigateway']
              subscriptionfilterarray = ['cloudwatch-lambda','cloudwatch-elasticsearch','rdsosmetrics','rdslogs','cloudwatch','cloudwatch-events','cloudwatch']

              try:
                  region = event['region']
                  detail = event['detail']
                  eventname = detail['eventName']

                  logger.info('region: ' + str(region))
                  logger.info('eventName: ' + str(eventname))
                  logger.info('detail: ' + str(detail))

                  if not detail['requestParameters']:
                      logger.warning('No responseElements found')
                      if detail['errorCode']:
                          logger.error('errorCode: ' + detail['errorCode'])
                      if detail['errorMessage']:
                          logger.error('errorMessage: ' + detail['errorMessage'])
                      return False

                  logGroupName = detail['requestParameters']['logGroupName']
                  logger.info(logGroupName)
                  filterresponseData = {}
                  for loggroup in loggrouparray:
                      if loggroup in logGroupName:
                          loggroupindex = loggrouparray.index(loggroup)
                          logger.info(loggroupindex)
                          filterName =  '{0}-{1}-{2}'.format(kinesisstreamprefix, filternamepostfixarray[loggroupindex], regiondict[region])
                          logger.info(filterName)
                          destinationARN = 'arn:aws:logs:{0}:{1}:destination:{2}-{3}-{4}'.format(region, KinesisAccount, kinesisstreamprefix, subscriptionfilterarray[loggroupindex], regiondict[region])
                          logger.info(destinationARN)
                          create_filter_response = create_subscription_filters(filterName,destinationARN,logGroupName,region)
                          logger.info("Create filter response "+str(create_filter_response))
                          logger.info(create_filter_response['ResponseMetadata']['HTTPStatusCode'])
                          if '200' in str(create_filter_response['ResponseMetadata']['HTTPStatusCode']):
                              is_subscription_filter_created = True
                          break 
                  logger.info(is_subscription_filter_created)
                  event['is_subscription_filter_created'] = is_subscription_filter_created
              except Exception as e:
                  logger.error('Something went wrong: ' + str(e))
                  return False
  LFCWApplySubFilterLG:
    Type: 'AWS::Logs::LogGroup'
    DependsOn: LFCWApplySubFilter
    Properties:
      LogGroupName:
        'Fn::Join':
          - ''
          - - /aws/lambda/
            - Ref: LFCWApplySubFilter
      RetentionInDays: 14
  PermissionForCWLogEventsToInvokeLambda:
    Type: 'AWS::Lambda::Permission'
    Properties:
      FunctionName: 
        Ref: LFCWApplySubFilter
      Action: 'lambda:InvokeFunction'
      Principal: events.amazonaws.com
      SourceArn:
        Fn::GetAtt:
          - CWLogEventRule
          - Arn
  LFCWApplySubFilterRole:
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Policies:
        - PolicyName: LFCWApplySubFilterPolicy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Sid: Stmt1458923121000
                Effect: Allow
                Action:
                  - 'logs:PutSubscriptionFilter'
                  - 'logs:CreateLogGroup'
                  - 'logs:CreateLogStream'
                  - 'logs:PutLogEvents'
                Resource:
                  - '*'